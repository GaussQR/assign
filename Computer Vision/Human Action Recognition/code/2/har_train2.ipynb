{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"har_train2.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"Ns04iKtJV7C9","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TosX-GB5V79I","colab_type":"code","colab":{}},"source":["cd /content/gdrive/My\\ Drive/Data\\ Sets"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PpR0lHpYV-Zd","colab_type":"code","outputId":"49a21182-d9df-4b4b-9918-32e195c776a8","executionInfo":{"status":"ok","timestamp":1571047525040,"user_tz":-330,"elapsed":5713,"user":{"displayName":"DEEPAK PANT","photoUrl":"","userId":"09691216020117759359"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":[""],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"M5Fjo7sYWxqv","colab_type":"code","colab":{}},"source":["train = pd.read_csv('train_01/train_new.csv')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KsCLOxtfg4nz","colab_type":"code","outputId":"6e0a662d-ad61-4d6b-fdb1-b9e0a1cb73b1","executionInfo":{"status":"ok","timestamp":1571052745622,"user_tz":-330,"elapsed":1563393,"user":{"displayName":"DEEPAK PANT","photoUrl":"","userId":"09691216020117759359"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["train_image = []\n","for i in tqdm(range(train.shape[0])):\n","    if i%3 != 0: continue\n","    img = image.load_img('train_01/'+train['image'][i], target_size=(224,224,3))\n","    img = image.img_to_array(img) / 255\n","    train_image.append(img)\n","train_image = np.array(train_image)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100%|██████████| 33801/33801 [1:25:59<00:00,  6.55it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"SRSErvvu6Pqh","colab_type":"code","colab":{}},"source":["#np.save('train_image', train_image, fix_imports='false')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5VP6cNH2F0fo","colab_type":"code","colab":{}},"source":["y_ = train['class']\n","y = []\n","for i in range(len(y_)):\n","    if i%3 == 0: y.append(y_[i])\n","X_train, X_test, y_train, y_test = train_test_split(train_image, y, random_state=100, stratify = y, test_size=0.2)\n","y_train = pd.get_dummies(y_train)\n","y_test = pd.get_dummies(y_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cDswrGatF0l-","colab_type":"code","outputId":"b178547f-59b4-423c-e1c7-48125ae6a09b","executionInfo":{"status":"ok","timestamp":1571057261898,"user_tz":-330,"elapsed":487400,"user":{"displayName":"DEEPAK PANT","photoUrl":"","userId":"09691216020117759359"}},"colab":{"base_uri":"https://localhost:8080/","height":423}},"source":["init_model = VGG19(weights='imagenet', include_top=False)\n","X_train = init_model.predict(X_train)\n","X_test = init_model.predict(X_test)\n","X_train = X_train.reshape(X_train.shape[0], X_train.shape[1]*X_train.shape[2]*X_train.shape[3])\n","X_test = X_test.reshape(X_test.shape[0], X_test.shape[1]*X_test.shape[2]*X_test.shape[3])\n","mx_train = X_train.max()\n","X_train /= mx_train\n","X_test /= mx_train\n","print(X_train.shape, X_test.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n","80142336/80134624 [==============================] - 2s 0us/step\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","(9013, 25088) (2254, 25088)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FiN3mSKoF0tQ","colab_type":"code","outputId":"7dcaca98-0367-463b-86df-e987d98b7a0a","executionInfo":{"status":"ok","timestamp":1571057261916,"user_tz":-330,"elapsed":459774,"user":{"displayName":"DEEPAK PANT","photoUrl":"","userId":"09691216020117759359"}},"colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["model = keras.models.Sequential([\n","    Dense(512, activation='relu', input_dim=X_train.shape[1]),\n","    Dropout(0.4),\n","    Dense(256, activation='relu'),\n","    Dropout(0.4),\n","    Dense(128, activation='relu'),\n","    Dropout(0.4),\n","    Dense(101, activation='softmax'),\n","])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"W88Opg46F01T","colab_type":"code","outputId":"56dfa8fd-f548-4d63-d75c-20aec1bdb21c","executionInfo":{"status":"ok","timestamp":1571057891197,"user_tz":-330,"elapsed":1087535,"user":{"displayName":"DEEPAK PANT","photoUrl":"","userId":"09691216020117759359"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["from keras.callbacks import ModelCheckpoint\n","mcp_save = ModelCheckpoint('weights2.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n","model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])\n","model.fit(X_train, y_train, epochs=150, validation_data=(X_test, y_test), callbacks=[mcp_save], batch_size=256)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","Train on 9013 samples, validate on 2254 samples\n","Epoch 1/150\n","9013/9013 [==============================] - 5s 516us/step - loss: 4.5482 - acc: 0.0207 - val_loss: 4.3749 - val_acc: 0.0577\n","Epoch 2/150\n","9013/9013 [==============================] - 4s 417us/step - loss: 4.2214 - acc: 0.0773 - val_loss: 3.8325 - val_acc: 0.1735\n","Epoch 3/150\n","9013/9013 [==============================] - 3s 379us/step - loss: 3.7318 - acc: 0.1579 - val_loss: 3.1838 - val_acc: 0.2995\n","Epoch 4/150\n","9013/9013 [==============================] - 3s 382us/step - loss: 3.2153 - acc: 0.2390 - val_loss: 2.6256 - val_acc: 0.3869\n","Epoch 5/150\n","9013/9013 [==============================] - 4s 399us/step - loss: 2.7905 - acc: 0.3189 - val_loss: 2.2131 - val_acc: 0.4876\n","Epoch 6/150\n","9013/9013 [==============================] - 4s 391us/step - loss: 2.4239 - acc: 0.3901 - val_loss: 1.9502 - val_acc: 0.5563\n","Epoch 7/150\n","9013/9013 [==============================] - 4s 430us/step - loss: 2.1360 - acc: 0.4410 - val_loss: 1.6601 - val_acc: 0.6127\n","Epoch 8/150\n","9013/9013 [==============================] - 4s 407us/step - loss: 1.9019 - acc: 0.4982 - val_loss: 1.5517 - val_acc: 0.6380\n","Epoch 9/150\n","9013/9013 [==============================] - 4s 413us/step - loss: 1.7286 - acc: 0.5332 - val_loss: 1.3905 - val_acc: 0.6748\n","Epoch 10/150\n","9013/9013 [==============================] - 4s 419us/step - loss: 1.5346 - acc: 0.5784 - val_loss: 1.2583 - val_acc: 0.6921\n","Epoch 11/150\n","9013/9013 [==============================] - 4s 399us/step - loss: 1.3912 - acc: 0.6126 - val_loss: 1.1828 - val_acc: 0.7130\n","Epoch 12/150\n","9013/9013 [==============================] - 4s 435us/step - loss: 1.2619 - acc: 0.6477 - val_loss: 1.1210 - val_acc: 0.7276\n","Epoch 13/150\n","9013/9013 [==============================] - 4s 453us/step - loss: 1.1438 - acc: 0.6738 - val_loss: 1.0545 - val_acc: 0.7467\n","Epoch 14/150\n","9013/9013 [==============================] - 4s 449us/step - loss: 1.0777 - acc: 0.6942 - val_loss: 1.0159 - val_acc: 0.7347\n","Epoch 15/150\n","9013/9013 [==============================] - 4s 435us/step - loss: 0.9576 - acc: 0.7230 - val_loss: 0.9358 - val_acc: 0.7640\n","Epoch 16/150\n","9013/9013 [==============================] - 4s 452us/step - loss: 0.9032 - acc: 0.7362 - val_loss: 0.9550 - val_acc: 0.7578\n","Epoch 17/150\n","9013/9013 [==============================] - 4s 448us/step - loss: 0.8471 - acc: 0.7469 - val_loss: 0.9192 - val_acc: 0.7644\n","Epoch 18/150\n","9013/9013 [==============================] - 4s 448us/step - loss: 0.7775 - acc: 0.7642 - val_loss: 0.9014 - val_acc: 0.7706\n","Epoch 19/150\n","9013/9013 [==============================] - 4s 460us/step - loss: 0.7189 - acc: 0.7885 - val_loss: 0.8816 - val_acc: 0.7808\n","Epoch 20/150\n","9013/9013 [==============================] - 4s 449us/step - loss: 0.6576 - acc: 0.8021 - val_loss: 0.8564 - val_acc: 0.7817\n","Epoch 21/150\n","9013/9013 [==============================] - 4s 445us/step - loss: 0.6302 - acc: 0.8097 - val_loss: 0.8657 - val_acc: 0.7853\n","Epoch 22/150\n","9013/9013 [==============================] - 4s 452us/step - loss: 0.6212 - acc: 0.8115 - val_loss: 0.8079 - val_acc: 0.7950\n","Epoch 23/150\n","9013/9013 [==============================] - 4s 443us/step - loss: 0.5754 - acc: 0.8276 - val_loss: 0.8274 - val_acc: 0.7946\n","Epoch 24/150\n","9013/9013 [==============================] - 4s 446us/step - loss: 0.5432 - acc: 0.8345 - val_loss: 0.8367 - val_acc: 0.7902\n","Epoch 25/150\n","9013/9013 [==============================] - 4s 419us/step - loss: 0.5283 - acc: 0.8395 - val_loss: 0.8071 - val_acc: 0.7986\n","Epoch 26/150\n","9013/9013 [==============================] - 4s 422us/step - loss: 0.4660 - acc: 0.8559 - val_loss: 0.7909 - val_acc: 0.8048\n","Epoch 27/150\n","9013/9013 [==============================] - 4s 436us/step - loss: 0.4672 - acc: 0.8574 - val_loss: 0.8598 - val_acc: 0.7972\n","Epoch 28/150\n","9013/9013 [==============================] - 4s 422us/step - loss: 0.4473 - acc: 0.8641 - val_loss: 0.7998 - val_acc: 0.8066\n","Epoch 29/150\n","9013/9013 [==============================] - 4s 442us/step - loss: 0.4208 - acc: 0.8699 - val_loss: 0.7900 - val_acc: 0.8114\n","Epoch 30/150\n","9013/9013 [==============================] - 4s 401us/step - loss: 0.4158 - acc: 0.8693 - val_loss: 0.8287 - val_acc: 0.8004\n","Epoch 31/150\n","9013/9013 [==============================] - 4s 426us/step - loss: 0.4183 - acc: 0.8644 - val_loss: 0.8166 - val_acc: 0.8052\n","Epoch 32/150\n","9013/9013 [==============================] - 4s 457us/step - loss: 0.4042 - acc: 0.8765 - val_loss: 0.7709 - val_acc: 0.8101\n","Epoch 33/150\n","9013/9013 [==============================] - 4s 419us/step - loss: 0.3855 - acc: 0.8831 - val_loss: 0.8241 - val_acc: 0.8070\n","Epoch 34/150\n","9013/9013 [==============================] - 4s 438us/step - loss: 0.3570 - acc: 0.8889 - val_loss: 0.8117 - val_acc: 0.8030\n","Epoch 35/150\n","9013/9013 [==============================] - 4s 455us/step - loss: 0.3280 - acc: 0.8979 - val_loss: 0.8089 - val_acc: 0.8137\n","Epoch 36/150\n","9013/9013 [==============================] - 4s 416us/step - loss: 0.3056 - acc: 0.9054 - val_loss: 0.8002 - val_acc: 0.8199\n","Epoch 37/150\n","9013/9013 [==============================] - 4s 427us/step - loss: 0.3051 - acc: 0.9066 - val_loss: 0.7935 - val_acc: 0.8154\n","Epoch 38/150\n","9013/9013 [==============================] - 4s 423us/step - loss: 0.2985 - acc: 0.9095 - val_loss: 0.8232 - val_acc: 0.8106\n","Epoch 39/150\n","9013/9013 [==============================] - 4s 428us/step - loss: 0.2775 - acc: 0.9139 - val_loss: 0.8536 - val_acc: 0.8137\n","Epoch 40/150\n","9013/9013 [==============================] - 4s 430us/step - loss: 0.2776 - acc: 0.9127 - val_loss: 0.8197 - val_acc: 0.8132\n","Epoch 41/150\n","9013/9013 [==============================] - 4s 436us/step - loss: 0.2953 - acc: 0.9089 - val_loss: 0.8072 - val_acc: 0.8221\n","Epoch 42/150\n","9013/9013 [==============================] - 4s 420us/step - loss: 0.2724 - acc: 0.9161 - val_loss: 0.8177 - val_acc: 0.8106\n","Epoch 43/150\n","9013/9013 [==============================] - 4s 475us/step - loss: 0.2634 - acc: 0.9172 - val_loss: 0.8110 - val_acc: 0.8172\n","Epoch 44/150\n","9013/9013 [==============================] - 4s 461us/step - loss: 0.2280 - acc: 0.9304 - val_loss: 0.8316 - val_acc: 0.8234\n","Epoch 45/150\n","9013/9013 [==============================] - 4s 433us/step - loss: 0.2474 - acc: 0.9214 - val_loss: 0.8181 - val_acc: 0.8154\n","Epoch 46/150\n","9013/9013 [==============================] - 4s 438us/step - loss: 0.2350 - acc: 0.9267 - val_loss: 0.7981 - val_acc: 0.8212\n","Epoch 47/150\n","9013/9013 [==============================] - 4s 461us/step - loss: 0.2372 - acc: 0.9267 - val_loss: 0.8169 - val_acc: 0.8199\n","Epoch 48/150\n","9013/9013 [==============================] - 4s 428us/step - loss: 0.2477 - acc: 0.9232 - val_loss: 0.8463 - val_acc: 0.8181\n","Epoch 49/150\n","9013/9013 [==============================] - 4s 436us/step - loss: 0.2389 - acc: 0.9242 - val_loss: 0.8340 - val_acc: 0.8172\n","Epoch 50/150\n","9013/9013 [==============================] - 4s 455us/step - loss: 0.2391 - acc: 0.9227 - val_loss: 0.8334 - val_acc: 0.8203\n","Epoch 51/150\n","9013/9013 [==============================] - 5s 503us/step - loss: 0.2146 - acc: 0.9331 - val_loss: 0.8445 - val_acc: 0.8190\n","Epoch 52/150\n","9013/9013 [==============================] - 4s 470us/step - loss: 0.2318 - acc: 0.9283 - val_loss: 0.8343 - val_acc: 0.8217\n","Epoch 53/150\n","9013/9013 [==============================] - 4s 430us/step - loss: 0.2144 - acc: 0.9356 - val_loss: 0.8277 - val_acc: 0.8190\n","Epoch 54/150\n","9013/9013 [==============================] - 4s 425us/step - loss: 0.2218 - acc: 0.9301 - val_loss: 0.8270 - val_acc: 0.8234\n","Epoch 55/150\n","9013/9013 [==============================] - 4s 438us/step - loss: 0.2248 - acc: 0.9288 - val_loss: 0.8432 - val_acc: 0.8199\n","Epoch 56/150\n","9013/9013 [==============================] - 4s 426us/step - loss: 0.2450 - acc: 0.9232 - val_loss: 0.8157 - val_acc: 0.8217\n","Epoch 57/150\n","9013/9013 [==============================] - 4s 422us/step - loss: 0.2192 - acc: 0.9342 - val_loss: 0.8273 - val_acc: 0.8252\n","Epoch 58/150\n","9013/9013 [==============================] - 4s 431us/step - loss: 0.2078 - acc: 0.9314 - val_loss: 0.8383 - val_acc: 0.8248\n","Epoch 59/150\n","9013/9013 [==============================] - 4s 400us/step - loss: 0.1985 - acc: 0.9383 - val_loss: 0.8166 - val_acc: 0.8225\n","Epoch 60/150\n","9013/9013 [==============================] - 4s 399us/step - loss: 0.1850 - acc: 0.9450 - val_loss: 0.8399 - val_acc: 0.8305\n","Epoch 61/150\n","9013/9013 [==============================] - 4s 409us/step - loss: 0.1895 - acc: 0.9413 - val_loss: 0.8223 - val_acc: 0.8190\n","Epoch 62/150\n","9013/9013 [==============================] - 4s 437us/step - loss: 0.1930 - acc: 0.9405 - val_loss: 0.8291 - val_acc: 0.8239\n","Epoch 63/150\n","9013/9013 [==============================] - 4s 427us/step - loss: 0.1800 - acc: 0.9429 - val_loss: 0.8146 - val_acc: 0.8230\n","Epoch 64/150\n","9013/9013 [==============================] - 4s 412us/step - loss: 0.2002 - acc: 0.9372 - val_loss: 0.8161 - val_acc: 0.8292\n","Epoch 65/150\n","9013/9013 [==============================] - 4s 407us/step - loss: 0.1835 - acc: 0.9454 - val_loss: 0.8075 - val_acc: 0.8243\n","Epoch 66/150\n","9013/9013 [==============================] - 4s 451us/step - loss: 0.1656 - acc: 0.9492 - val_loss: 0.7982 - val_acc: 0.8261\n","Epoch 67/150\n","9013/9013 [==============================] - 4s 444us/step - loss: 0.1725 - acc: 0.9469 - val_loss: 0.8583 - val_acc: 0.8261\n","Epoch 68/150\n","9013/9013 [==============================] - 4s 453us/step - loss: 0.1592 - acc: 0.9502 - val_loss: 0.8794 - val_acc: 0.8248\n","Epoch 69/150\n","9013/9013 [==============================] - 4s 467us/step - loss: 0.1722 - acc: 0.9482 - val_loss: 0.8268 - val_acc: 0.8279\n","Epoch 70/150\n","9013/9013 [==============================] - 4s 426us/step - loss: 0.1832 - acc: 0.9414 - val_loss: 0.8302 - val_acc: 0.8252\n","Epoch 71/150\n","9013/9013 [==============================] - 4s 494us/step - loss: 0.1743 - acc: 0.9446 - val_loss: 0.8552 - val_acc: 0.8194\n","Epoch 72/150\n","9013/9013 [==============================] - 4s 494us/step - loss: 0.1767 - acc: 0.9460 - val_loss: 0.8829 - val_acc: 0.8248\n","Epoch 73/150\n","9013/9013 [==============================] - 4s 471us/step - loss: 0.1565 - acc: 0.9504 - val_loss: 0.8646 - val_acc: 0.8283\n","Epoch 74/150\n","9013/9013 [==============================] - 4s 468us/step - loss: 0.1636 - acc: 0.9491 - val_loss: 0.8907 - val_acc: 0.8208\n","Epoch 75/150\n","9013/9013 [==============================] - 4s 437us/step - loss: 0.1640 - acc: 0.9490 - val_loss: 0.9071 - val_acc: 0.8283\n","Epoch 76/150\n","9013/9013 [==============================] - 4s 425us/step - loss: 0.1488 - acc: 0.9562 - val_loss: 0.8875 - val_acc: 0.8274\n","Epoch 77/150\n","9013/9013 [==============================] - 4s 430us/step - loss: 0.1531 - acc: 0.9504 - val_loss: 0.8908 - val_acc: 0.8221\n","Epoch 78/150\n","9013/9013 [==============================] - 4s 436us/step - loss: 0.1761 - acc: 0.9441 - val_loss: 0.8563 - val_acc: 0.8190\n","Epoch 79/150\n","9013/9013 [==============================] - 4s 422us/step - loss: 0.1539 - acc: 0.9497 - val_loss: 0.8649 - val_acc: 0.8221\n","Epoch 80/150\n","9013/9013 [==============================] - 4s 428us/step - loss: 0.1885 - acc: 0.9427 - val_loss: 0.8892 - val_acc: 0.8190\n","Epoch 81/150\n","9013/9013 [==============================] - 4s 445us/step - loss: 0.1753 - acc: 0.9461 - val_loss: 0.8565 - val_acc: 0.8230\n","Epoch 82/150\n","9013/9013 [==============================] - 4s 436us/step - loss: 0.1744 - acc: 0.9427 - val_loss: 0.8787 - val_acc: 0.8194\n","Epoch 83/150\n","9013/9013 [==============================] - 4s 472us/step - loss: 0.1738 - acc: 0.9482 - val_loss: 0.8715 - val_acc: 0.8234\n","Epoch 84/150\n","9013/9013 [==============================] - 4s 460us/step - loss: 0.1575 - acc: 0.9516 - val_loss: 0.8284 - val_acc: 0.8252\n","Epoch 85/150\n","9013/9013 [==============================] - 4s 417us/step - loss: 0.1529 - acc: 0.9522 - val_loss: 0.8869 - val_acc: 0.8234\n","Epoch 86/150\n","9013/9013 [==============================] - 4s 421us/step - loss: 0.1611 - acc: 0.9487 - val_loss: 0.8360 - val_acc: 0.8336\n","Epoch 87/150\n","9013/9013 [==============================] - 4s 429us/step - loss: 0.1607 - acc: 0.9500 - val_loss: 0.8795 - val_acc: 0.8239\n","Epoch 88/150\n","9013/9013 [==============================] - 4s 422us/step - loss: 0.1375 - acc: 0.9558 - val_loss: 0.9079 - val_acc: 0.8203\n","Epoch 89/150\n","9013/9013 [==============================] - 4s 449us/step - loss: 0.1549 - acc: 0.9504 - val_loss: 0.8590 - val_acc: 0.8305\n","Epoch 90/150\n","9013/9013 [==============================] - 4s 445us/step - loss: 0.1447 - acc: 0.9553 - val_loss: 0.8847 - val_acc: 0.8310\n","Epoch 91/150\n","9013/9013 [==============================] - 4s 477us/step - loss: 0.1545 - acc: 0.9524 - val_loss: 0.9385 - val_acc: 0.8190\n","Epoch 92/150\n","9013/9013 [==============================] - 4s 456us/step - loss: 0.1602 - acc: 0.9497 - val_loss: 0.9054 - val_acc: 0.8239\n","Epoch 93/150\n","9013/9013 [==============================] - 5s 509us/step - loss: 0.1629 - acc: 0.9508 - val_loss: 0.9121 - val_acc: 0.8146\n","Epoch 94/150\n","9013/9013 [==============================] - 4s 446us/step - loss: 0.1651 - acc: 0.9484 - val_loss: 0.8884 - val_acc: 0.8283\n","Epoch 95/150\n","9013/9013 [==============================] - 4s 474us/step - loss: 0.1550 - acc: 0.9528 - val_loss: 0.9076 - val_acc: 0.8292\n","Epoch 96/150\n","9013/9013 [==============================] - 4s 481us/step - loss: 0.1419 - acc: 0.9565 - val_loss: 0.9095 - val_acc: 0.8199\n","Epoch 97/150\n","9013/9013 [==============================] - 5s 503us/step - loss: 0.1537 - acc: 0.9520 - val_loss: 0.9037 - val_acc: 0.8217\n","Epoch 98/150\n","9013/9013 [==============================] - 4s 467us/step - loss: 0.1738 - acc: 0.9463 - val_loss: 0.8658 - val_acc: 0.8163\n","Epoch 99/150\n","9013/9013 [==============================] - 4s 450us/step - loss: 0.1783 - acc: 0.9460 - val_loss: 0.8197 - val_acc: 0.8301\n","Epoch 100/150\n","9013/9013 [==============================] - 4s 413us/step - loss: 0.1518 - acc: 0.9525 - val_loss: 0.8505 - val_acc: 0.8261\n","Epoch 101/150\n","9013/9013 [==============================] - 4s 415us/step - loss: 0.1846 - acc: 0.9418 - val_loss: 0.8900 - val_acc: 0.8208\n","Epoch 102/150\n","9013/9013 [==============================] - 4s 412us/step - loss: 0.1800 - acc: 0.9469 - val_loss: 0.8601 - val_acc: 0.8287\n","Epoch 103/150\n","9013/9013 [==============================] - 4s 433us/step - loss: 0.1493 - acc: 0.9536 - val_loss: 0.8935 - val_acc: 0.8208\n","Epoch 104/150\n","9013/9013 [==============================] - 4s 412us/step - loss: 0.1670 - acc: 0.9499 - val_loss: 0.8804 - val_acc: 0.8314\n","Epoch 105/150\n","9013/9013 [==============================] - 4s 414us/step - loss: 0.1646 - acc: 0.9512 - val_loss: 0.8275 - val_acc: 0.8270\n","Epoch 106/150\n","9013/9013 [==============================] - 4s 436us/step - loss: 0.1498 - acc: 0.9548 - val_loss: 0.8918 - val_acc: 0.8270\n","Epoch 107/150\n","9013/9013 [==============================] - 4s 472us/step - loss: 0.1361 - acc: 0.9568 - val_loss: 0.8874 - val_acc: 0.8270\n","Epoch 108/150\n","9013/9013 [==============================] - 4s 441us/step - loss: 0.1492 - acc: 0.9541 - val_loss: 0.9116 - val_acc: 0.8239\n","Epoch 109/150\n","9013/9013 [==============================] - 4s 446us/step - loss: 0.1371 - acc: 0.9582 - val_loss: 0.9255 - val_acc: 0.8279\n","Epoch 110/150\n","9013/9013 [==============================] - 4s 421us/step - loss: 0.1356 - acc: 0.9567 - val_loss: 0.8654 - val_acc: 0.8319\n","Epoch 111/150\n","9013/9013 [==============================] - 4s 404us/step - loss: 0.1427 - acc: 0.9541 - val_loss: 0.8762 - val_acc: 0.8292\n","Epoch 112/150\n","9013/9013 [==============================] - 4s 413us/step - loss: 0.1156 - acc: 0.9659 - val_loss: 0.9010 - val_acc: 0.8319\n","Epoch 113/150\n","9013/9013 [==============================] - 4s 456us/step - loss: 0.1458 - acc: 0.9534 - val_loss: 0.9093 - val_acc: 0.8279\n","Epoch 114/150\n","9013/9013 [==============================] - 4s 442us/step - loss: 0.1719 - acc: 0.9477 - val_loss: 0.8955 - val_acc: 0.8212\n","Epoch 115/150\n","9013/9013 [==============================] - 4s 416us/step - loss: 0.1346 - acc: 0.9594 - val_loss: 0.9019 - val_acc: 0.8345\n","Epoch 116/150\n","9013/9013 [==============================] - 4s 464us/step - loss: 0.1210 - acc: 0.9653 - val_loss: 0.9690 - val_acc: 0.8296\n","Epoch 117/150\n","9013/9013 [==============================] - 4s 467us/step - loss: 0.1249 - acc: 0.9605 - val_loss: 0.9881 - val_acc: 0.8248\n","Epoch 118/150\n","9013/9013 [==============================] - 4s 422us/step - loss: 0.1203 - acc: 0.9629 - val_loss: 0.9153 - val_acc: 0.8283\n","Epoch 119/150\n","9013/9013 [==============================] - 4s 421us/step - loss: 0.1523 - acc: 0.9564 - val_loss: 0.8824 - val_acc: 0.8287\n","Epoch 120/150\n","9013/9013 [==============================] - 4s 407us/step - loss: 0.1252 - acc: 0.9611 - val_loss: 0.8671 - val_acc: 0.8341\n","Epoch 121/150\n","9013/9013 [==============================] - 4s 419us/step - loss: 0.1437 - acc: 0.9554 - val_loss: 0.8946 - val_acc: 0.8239\n","Epoch 122/150\n","9013/9013 [==============================] - 4s 416us/step - loss: 0.1410 - acc: 0.9555 - val_loss: 0.8674 - val_acc: 0.8256\n","Epoch 123/150\n","9013/9013 [==============================] - 4s 413us/step - loss: 0.1217 - acc: 0.9626 - val_loss: 0.8959 - val_acc: 0.8301\n","Epoch 124/150\n","9013/9013 [==============================] - 4s 411us/step - loss: 0.1177 - acc: 0.9614 - val_loss: 0.9277 - val_acc: 0.8230\n","Epoch 125/150\n","9013/9013 [==============================] - 4s 432us/step - loss: 0.1335 - acc: 0.9602 - val_loss: 0.8602 - val_acc: 0.8319\n","Epoch 126/150\n","9013/9013 [==============================] - 4s 430us/step - loss: 0.1131 - acc: 0.9647 - val_loss: 0.8890 - val_acc: 0.8279\n","Epoch 127/150\n","9013/9013 [==============================] - 4s 420us/step - loss: 0.1024 - acc: 0.9670 - val_loss: 0.8579 - val_acc: 0.8332\n","Epoch 128/150\n","9013/9013 [==============================] - 4s 435us/step - loss: 0.1062 - acc: 0.9678 - val_loss: 0.9148 - val_acc: 0.8292\n","Epoch 129/150\n","9013/9013 [==============================] - 4s 439us/step - loss: 0.1419 - acc: 0.9550 - val_loss: 0.8772 - val_acc: 0.8292\n","Epoch 130/150\n","9013/9013 [==============================] - 4s 401us/step - loss: 0.1339 - acc: 0.9602 - val_loss: 0.8497 - val_acc: 0.8305\n","Epoch 131/150\n","9013/9013 [==============================] - 4s 476us/step - loss: 0.1138 - acc: 0.9637 - val_loss: 0.8464 - val_acc: 0.8319\n","Epoch 132/150\n","9013/9013 [==============================] - 5s 503us/step - loss: 0.1213 - acc: 0.9622 - val_loss: 0.8870 - val_acc: 0.8314\n","Epoch 133/150\n","9013/9013 [==============================] - 4s 462us/step - loss: 0.1317 - acc: 0.9595 - val_loss: 0.9143 - val_acc: 0.8243\n","Epoch 134/150\n","9013/9013 [==============================] - 4s 461us/step - loss: 0.1652 - acc: 0.9460 - val_loss: 0.8696 - val_acc: 0.8319\n","Epoch 135/150\n","9013/9013 [==============================] - 4s 456us/step - loss: 0.1341 - acc: 0.9597 - val_loss: 0.9153 - val_acc: 0.8270\n","Epoch 136/150\n","9013/9013 [==============================] - 4s 425us/step - loss: 0.1064 - acc: 0.9670 - val_loss: 0.8585 - val_acc: 0.8376\n","Epoch 137/150\n","9013/9013 [==============================] - 4s 421us/step - loss: 0.1151 - acc: 0.9634 - val_loss: 0.9179 - val_acc: 0.8230\n","Epoch 138/150\n","9013/9013 [==============================] - 4s 424us/step - loss: 0.1240 - acc: 0.9626 - val_loss: 0.8703 - val_acc: 0.8301\n","Epoch 139/150\n","9013/9013 [==============================] - 4s 440us/step - loss: 0.1127 - acc: 0.9663 - val_loss: 0.8731 - val_acc: 0.8385\n","Epoch 140/150\n","9013/9013 [==============================] - 4s 403us/step - loss: 0.1303 - acc: 0.9603 - val_loss: 0.9087 - val_acc: 0.8279\n","Epoch 141/150\n","9013/9013 [==============================] - 4s 413us/step - loss: 0.1367 - acc: 0.9576 - val_loss: 0.9477 - val_acc: 0.8305\n","Epoch 142/150\n","9013/9013 [==============================] - 4s 391us/step - loss: 0.1455 - acc: 0.9531 - val_loss: 0.9168 - val_acc: 0.8159\n","Epoch 143/150\n","9013/9013 [==============================] - 3s 381us/step - loss: 0.1312 - acc: 0.9582 - val_loss: 0.9366 - val_acc: 0.8292\n","Epoch 144/150\n","9013/9013 [==============================] - 4s 411us/step - loss: 0.1277 - acc: 0.9596 - val_loss: 0.9041 - val_acc: 0.8239\n","Epoch 145/150\n","9013/9013 [==============================] - 4s 424us/step - loss: 0.1333 - acc: 0.9605 - val_loss: 0.8994 - val_acc: 0.8314\n","Epoch 146/150\n","9013/9013 [==============================] - 4s 440us/step - loss: 0.1332 - acc: 0.9593 - val_loss: 0.9080 - val_acc: 0.8199\n","Epoch 147/150\n","9013/9013 [==============================] - 4s 433us/step - loss: 0.1321 - acc: 0.9573 - val_loss: 0.9003 - val_acc: 0.8256\n","Epoch 148/150\n","9013/9013 [==============================] - 4s 402us/step - loss: 0.1283 - acc: 0.9613 - val_loss: 0.9009 - val_acc: 0.8185\n","Epoch 149/150\n","9013/9013 [==============================] - 4s 416us/step - loss: 0.1193 - acc: 0.9615 - val_loss: 0.8849 - val_acc: 0.8314\n","Epoch 150/150\n","9013/9013 [==============================] - 4s 398us/step - loss: 0.1268 - acc: 0.9624 - val_loss: 0.8818 - val_acc: 0.8345\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f371c28fc88>"]},"metadata":{"tags":[]},"execution_count":12}]}]}